{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "44-animal-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Gs5547AVwkVxZvvMfMOxI0vN3oghKcwp",
      "authorship_tag": "ABX9TyNKjmOdBGAYAs0Bf4/Ji8jb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebadi-Fereshteh/Deep-Learning/blob/main/Deep-Learning/44-animalDetector-cnn/44_animal_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "QasHudH9Sl12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xHZmGicOR_y9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_preprocess(image):\n",
        "  image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "  return image"
      ],
      "metadata": {
        "id": "zEK8iPR1fqh3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "kwzzkxBGFItg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gkyqhztWX4O",
        "outputId": "fe63d9f0-9297-44a6-ceca-44ac214129dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/datasets/animal\"\n",
        "width = height = 224\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    # Augmentation\n",
        "    horizontal_flip = True,\n",
        "    zoom_range=0.1,\n",
        "    rotation_range = 15,\n",
        "    brightness_range = (0.9, 1.1),\n",
        "    # preprocessing_function = my_preprocess\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width, height),\n",
        "    class_mode = \"categorical\",\n",
        "    subset= \"training\",\n",
        "    save_to_dir = \"/content/drive/MyDrive/datasets/augmentation_animal\"\n",
        ")\n",
        "\n",
        "val_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(width, height),\n",
        "    class_mode= \"categorical\",\n",
        "    subset= \"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N06jEyiFLTM",
        "outputId": "02a0a724-d7fd-4025-9280-e5c1c7202d27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1061 images belonging to 5 classes.\n",
            "Found 263 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=( width, height, 3)),\n",
        "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPool2D(),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256, activation=\"relu\"),\n",
        "        Dense(5, activation=\"softmax\"),\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "wMTI2jOQXUuM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= tf.keras.optimizers.Adam(),\n",
        "              loss= tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "9-z8_cfPSe1N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, epochs= 10, validation_data= val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsMW3GPSaRxG",
        "outputId": "910eefb9-a102-40f6-9fe3-5975e04fea11"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.8395 - accuracy: 0.6673 - val_loss: 1.0926 - val_accuracy: 0.5894\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.7494 - accuracy: 0.7154 - val_loss: 0.9602 - val_accuracy: 0.6540\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.6845 - accuracy: 0.7257 - val_loss: 1.1223 - val_accuracy: 0.5856\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.7027 - accuracy: 0.7191 - val_loss: 1.0196 - val_accuracy: 0.5627\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.6330 - accuracy: 0.7615 - val_loss: 0.9782 - val_accuracy: 0.6236\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.5590 - accuracy: 0.7832 - val_loss: 1.0767 - val_accuracy: 0.6502\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.4581 - accuracy: 0.8322 - val_loss: 1.0656 - val_accuracy: 0.6616\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.4339 - accuracy: 0.8294 - val_loss: 1.1293 - val_accuracy: 0.6578\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.5172 - accuracy: 0.8021 - val_loss: 1.0430 - val_accuracy: 0.6198\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.4530 - accuracy: 0.8341 - val_loss: 1.1609 - val_accuracy: 0.6198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bb0125e10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "5_hEtv7WdgLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/datasets/animal/test\"\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./ 255,\n",
        ")\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width, height),\n",
        "    class_mode = \"categorical\",\n",
        ")"
      ],
      "metadata": {
        "id": "xeFtiYbjcMmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "X8zRiBdKeRfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(model.history['accuracy'], label='accuracy')\n",
        "# plt.plot(model.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Train')\n",
        "# plt.ylim([0.5, 1])\n",
        "# plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "1cYkfta5uS-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/models/44-animal-cnn.h5\")"
      ],
      "metadata": {
        "id": "O40annoQuphU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "OJz6kOECeWfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"/content/Giraffa.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (width, height))\n",
        "image = image / 255\n",
        "image = image.reshape(1, width, height, 3)  # 3d -> 4D\n",
        "\n",
        "result = model.predict(image)\n",
        "print(result)\n",
        "pred = np.argmax(result)\n",
        "\n",
        "if pred == 0:\n",
        "  print(\"üê±\")\n",
        "  #  print(\"\\U0001F431\")\n",
        "elif pred==1:\n",
        "  print(\"üê∂\")\n",
        "  # print(\"\\U0001F436\")\n",
        "elif pred==2:\n",
        "  print(\"üêò\")\n",
        "elif pred==3:\n",
        "  print(\"ü¶í\")\n",
        "  # print(\"\\U0001F992\")  \n",
        "elif pred==4:\n",
        "  print(\"üêº\")\n",
        "  # print(\"\\U0001F43C\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrVAz0eEeabd",
        "outputId": "501b0561-10b2-4f15-c486-684138b648fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.1245427e-04 1.9137347e-04 7.5987302e-04 9.9882716e-01 9.1072989e-06]]\n",
            "ü¶í\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FiieiDBDwGID"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}